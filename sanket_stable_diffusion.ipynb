{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RC7V_td4DT3l",
        "outputId": "535b2706-e87d-4692-f44b-45a0f4c09762"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DnIycbnN2XQ",
        "outputId": "427dcd4a-69cc-4b2c-b58d-c94991cbe3e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/sanket_stable_model\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/sanket_stable_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bpn_wwTsN4Og",
        "outputId": "27bd67f3-ee9b-4ea8-fdeb-2f2d1f331242"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mimages\u001b[0m/  \u001b[01;34moutput\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FtFx0mMOWWp",
        "outputId": "b220c37d-8479-4b28-aabd-64e908ef24f1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UsageError: %%capture is a cell magic, but the cell body is empty.\n"
          ]
        }
      ],
      "source": [
        "%%capture\n",
        "!pip install -U autotrain-advanced\n",
        "!autotrain setup --update-torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVEL0CPBOtpV",
        "outputId": "4167a680-01ed-42d1-a521-ef4cc64f4389"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "usage: autotrain <command> [<args>] dreambooth\n",
            "       [-h]\n",
            "       --model\n",
            "       MODEL\n",
            "       [--revision REVISION]\n",
            "       [--tokenizer TOKENIZER]\n",
            "       --image-path\n",
            "       IMAGE_PATH\n",
            "       [--class-image-path CLASS_IMAGE_PATH]\n",
            "       --prompt\n",
            "       PROMPT\n",
            "       [--class-prompt CLASS_PROMPT]\n",
            "       [--num-class-images NUM_CLASS_IMAGES]\n",
            "       [--class-labels-conditioning CLASS_LABELS_CONDITIONING]\n",
            "       [--prior-preservation]\n",
            "       [--prior-loss-weight PRIOR_LOSS_WEIGHT]\n",
            "       --project-name\n",
            "       PROJECT_NAME\n",
            "       [--seed SEED]\n",
            "       --resolution\n",
            "       RESOLUTION\n",
            "       [--center-crop]\n",
            "       [--train-text-encoder]\n",
            "       [--batch-size BATCH_SIZE]\n",
            "       [--sample-batch-size SAMPLE_BATCH_SIZE]\n",
            "       [--epochs EPOCHS]\n",
            "       [--num-steps NUM_STEPS]\n",
            "       [--checkpointing-steps CHECKPOINTING_STEPS]\n",
            "       [--resume-from-checkpoint RESUME_FROM_CHECKPOINT]\n",
            "       [--gradient-accumulation GRADIENT_ACCUMULATION]\n",
            "       [--gradient-checkpointing]\n",
            "       [--lr LR]\n",
            "       [--scale-lr]\n",
            "       [--scheduler SCHEDULER]\n",
            "       [--warmup-steps WARMUP_STEPS]\n",
            "       [--num-cycles NUM_CYCLES]\n",
            "       [--lr-power LR_POWER]\n",
            "       [--dataloader-num-workers DATALOADER_NUM_WORKERS]\n",
            "       [--use-8bit-adam]\n",
            "       [--adam-beta1 ADAM_BETA1]\n",
            "       [--adam-beta2 ADAM_BETA2]\n",
            "       [--adam-weight-decay ADAM_WEIGHT_DECAY]\n",
            "       [--adam-epsilon ADAM_EPSILON]\n",
            "       [--max-grad-norm MAX_GRAD_NORM]\n",
            "       [--allow-tf32]\n",
            "       [--prior-generation-precision PRIOR_GENERATION_PRECISION]\n",
            "       [--local-rank LOCAL_RANK]\n",
            "       [--xformers]\n",
            "       [--pre-compute-text-embeddings]\n",
            "       [--tokenizer-max-length TOKENIZER_MAX_LENGTH]\n",
            "       [--text-encoder-use-attention-mask]\n",
            "       [--rank RANK]\n",
            "       [--xl]\n",
            "       [--fp16]\n",
            "       [--bf16]\n",
            "       [--token TOKEN]\n",
            "       [--repo-id REPO_ID]\n",
            "       [--push-to-hub]\n",
            "       [--validation-prompt VALIDATION_PROMPT]\n",
            "       [--num-validation-images NUM_VALIDATION_IMAGES]\n",
            "       [--validation-epochs VALIDATION_EPOCHS]\n",
            "       [--checkpoints-total-limit CHECKPOINTS_TOTAL_LIMIT]\n",
            "       [--validation-images VALIDATION_IMAGES]\n",
            "       [--logging]\n",
            "       [--username USERNAME]\n",
            "\n",
            "✨ Run\n",
            "AutoTrain\n",
            "DreamBooth\n",
            "Training\n",
            "\n",
            "options:\n",
            "  -h, --help\n",
            "    show this\n",
            "    help\n",
            "    message and\n",
            "    exit\n",
            "  --model MODEL\n",
            "    Model to\n",
            "    use for\n",
            "    training\n",
            "  --revision REVISION\n",
            "    Model\n",
            "    revision to\n",
            "    use for\n",
            "    training\n",
            "  --tokenizer TOKENIZER\n",
            "    Tokenizer\n",
            "    to use for\n",
            "    training\n",
            "  --image-path IMAGE_PATH\n",
            "    Path to the\n",
            "    images\n",
            "  --class-image-path CLASS_IMAGE_PATH\n",
            "    Path to the\n",
            "    class\n",
            "    images\n",
            "  --prompt PROMPT\n",
            "    Instance\n",
            "    prompt\n",
            "  --class-prompt CLASS_PROMPT\n",
            "    Class\n",
            "    prompt\n",
            "  --num-class-images NUM_CLASS_IMAGES\n",
            "    Number of\n",
            "    class\n",
            "    images\n",
            "  --class-labels-conditioning CLASS_LABELS_CONDITIONING\n",
            "    Class\n",
            "    labels cond\n",
            "    itioning\n",
            "  --prior-preservation\n",
            "    With prior \n",
            "    preservatio\n",
            "    n\n",
            "  --prior-loss-weight PRIOR_LOSS_WEIGHT\n",
            "    Prior loss\n",
            "    weight\n",
            "  --project-name PROJECT_NAME\n",
            "    Output\n",
            "    directory\n",
            "    or repo id\n",
            "  --seed SEED\n",
            "    Seed\n",
            "  --resolution RESOLUTION\n",
            "    Resolution\n",
            "  --center-crop\n",
            "    Center crop\n",
            "  --train-text-encoder\n",
            "    Train text\n",
            "    encoder\n",
            "  --batch-size BATCH_SIZE\n",
            "    Train batch\n",
            "    size\n",
            "  --sample-batch-size SAMPLE_BATCH_SIZE\n",
            "    Sample\n",
            "    batch size\n",
            "  --epochs EPOCHS\n",
            "    Number of\n",
            "    training\n",
            "    epochs\n",
            "  --num-steps NUM_STEPS\n",
            "    Max train\n",
            "    steps\n",
            "  --checkpointing-steps CHECKPOINTING_STEPS\n",
            "    Checkpointi\n",
            "    ng steps\n",
            "  --resume-from-checkpoint RESUME_FROM_CHECKPOINT\n",
            "    Resume from\n",
            "    checkpoint\n",
            "  --gradient-accumulation GRADIENT_ACCUMULATION\n",
            "    Gradient ac\n",
            "    cumulation\n",
            "    steps\n",
            "  --gradient-checkpointing\n",
            "    Gradient ch\n",
            "    eckpointing\n",
            "  --lr LR\n",
            "    Learning\n",
            "    rate\n",
            "  --scale-lr\n",
            "    Scale\n",
            "    learning\n",
            "    rate\n",
            "  --scheduler SCHEDULER\n",
            "    Learning\n",
            "    rate\n",
            "    scheduler\n",
            "  --warmup-steps WARMUP_STEPS\n",
            "    Learning\n",
            "    rate warmup\n",
            "    steps\n",
            "  --num-cycles NUM_CYCLES\n",
            "    Learning\n",
            "    rate num\n",
            "    cycles\n",
            "  --lr-power LR_POWER\n",
            "    Learning\n",
            "    rate power\n",
            "  --dataloader-num-workers DATALOADER_NUM_WORKERS\n",
            "    Dataloader\n",
            "    num workers\n",
            "  --use-8bit-adam\n",
            "    Use 8bit\n",
            "    adam\n",
            "  --adam-beta1 ADAM_BETA1\n",
            "    Adam beta 1\n",
            "  --adam-beta2 ADAM_BETA2\n",
            "    Adam beta 2\n",
            "  --adam-weight-decay ADAM_WEIGHT_DECAY\n",
            "    Adam weight\n",
            "    decay\n",
            "  --adam-epsilon ADAM_EPSILON\n",
            "    Adam\n",
            "    epsilon\n",
            "  --max-grad-norm MAX_GRAD_NORM\n",
            "    Max grad\n",
            "    norm\n",
            "  --allow-tf32\n",
            "    Allow TF32\n",
            "  --prior-generation-precision PRIOR_GENERATION_PRECISION\n",
            "    Prior\n",
            "    generation\n",
            "    precision\n",
            "  --local-rank LOCAL_RANK\n",
            "    Local rank\n",
            "  --xformers\n",
            "    Enable\n",
            "    xformers\n",
            "    memory\n",
            "    efficient\n",
            "    attention\n",
            "  --pre-compute-text-embeddings\n",
            "    Pre compute\n",
            "    text\n",
            "    embeddings\n",
            "  --tokenizer-max-length TOKENIZER_MAX_LENGTH\n",
            "    Tokenizer\n",
            "    max length\n",
            "  --text-encoder-use-attention-mask\n",
            "    Text\n",
            "    encoder use\n",
            "    attention\n",
            "    mask\n",
            "  --rank RANK\n",
            "    Rank\n",
            "  --xl\n",
            "    XL\n",
            "  --fp16\n",
            "    FP16\n",
            "  --bf16\n",
            "    BF16\n",
            "  --token TOKEN\n",
            "    Hub token\n",
            "  --repo-id REPO_ID\n",
            "    Hub repo id\n",
            "  --push-to-hub\n",
            "    Push to hub\n",
            "  --validation-prompt VALIDATION_PROMPT\n",
            "    Validation\n",
            "    prompt\n",
            "  --num-validation-images NUM_VALIDATION_IMAGES\n",
            "    Number of\n",
            "    validation\n",
            "    images\n",
            "  --validation-epochs VALIDATION_EPOCHS\n",
            "    Validation\n",
            "    epochs\n",
            "  --checkpoints-total-limit CHECKPOINTS_TOTAL_LIMIT\n",
            "    Checkpoints\n",
            "    total limit\n",
            "  --validation-images VALIDATION_IMAGES\n",
            "    Validation\n",
            "    images\n",
            "  --logging\n",
            "    Logging\n",
            "    using\n",
            "    tensorboard\n",
            "  --username USERNAME\n",
            "    Hugging\n",
            "    Face Hub\n",
            "    Username\n"
          ]
        }
      ],
      "source": [
        "!autotrain dreambooth --help"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehinMngZO-dh",
        "outputId": "92f25b17-2045-4a0d-ba1d-2eb8dee6596b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mimages\u001b[0m/  \u001b[01;34moutput\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "gq1-Nt2GEMiS",
        "outputId": "1af25145-41fa-47a3-953c-3e15354b46e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> \u001b[1mINFO    Namespace(version=False, model='stabilityai/stable-diffusion-xl-base-1.0', revision=None, tokenizer=None, image_path='images/', class_image_path=None, prompt='photo of sankii man', class_prompt=None, num_class_images=100, class_labels_conditioning=None, prior_preservation=None, prior_loss_weight=1.0, project_name='output/', seed=42, resolution=512, center_crop=None, train_text_encoder=None, batch_size=1, sample_batch_size=4, epochs=1, num_steps=1000, checkpointing_steps=100000, resume_from_checkpoint=None, gradient_accumulation=4, gradient_checkpointing=None, lr=0.0001, scale_lr=None, scheduler='constant', warmup_steps=0, num_cycles=1, lr_power=1.0, dataloader_num_workers=0, use_8bit_adam=None, adam_beta1=0.9, adam_beta2=0.999, adam_weight_decay=0.01, adam_epsilon=1e-08, max_grad_norm=1.0, allow_tf32=None, prior_generation_precision=None, local_rank=-1, xformers=None, pre_compute_text_embeddings=None, tokenizer_max_length=None, text_encoder_use_attention_mask=None, rank=4, xl=None, fp16=True, bf16=None, token=None, repo_id=None, push_to_hub=None, validation_prompt=None, num_validation_images=4, validation_epochs=50, checkpoints_total_limit=None, validation_images=None, logging=None, username=None, func=<function run_dreambooth_command_factory at 0x7fd2253fde10>)\u001b[0m\n",
            "> \u001b[1mINFO    Running DreamBooth Training\u001b[0m\n",
            "> \u001b[33m\u001b[1mWARNING Parameters supplied but not used: version, func\u001b[0m\n",
            "Downloading (…)okenizer_config.json: 100% 737/737 [00:00<00:00, 4.15MB/s]\n",
            "Downloading (…)tokenizer/vocab.json: 100% 1.06M/1.06M [00:00<00:00, 3.97MB/s]\n",
            "Downloading (…)tokenizer/merges.txt: 100% 525k/525k [00:00<00:00, 3.98MB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 472/472 [00:00<00:00, 2.47MB/s]\n",
            "Downloading (…)okenizer_config.json: 100% 725/725 [00:00<00:00, 3.55MB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 460/460 [00:00<00:00, 2.29MB/s]\n",
            "Downloading (…)_encoder/config.json: 100% 565/565 [00:00<00:00, 2.88MB/s]\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "Downloading (…)ncoder_2/config.json: 100% 575/575 [00:00<00:00, 3.34MB/s]\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "Downloading model.safetensors: 100% 492M/492M [00:03<00:00, 131MB/s]\n",
            "Downloading model.safetensors: 100% 2.78G/2.78G [00:11<00:00, 245MB/s]\n",
            "Downloading (…)main/vae/config.json: 100% 642/642 [00:00<00:00, 3.59MB/s]\n",
            "Downloading (…)ch_model.safetensors: 100% 335M/335M [00:01<00:00, 266MB/s]\n",
            "Downloading (…)ain/unet/config.json: 100% 1.68k/1.68k [00:00<00:00, 9.76MB/s]\n",
            "Downloading (…)ch_model.safetensors: 100% 10.3G/10.3G [01:07<00:00, 152MB/s]\n",
            "{'dropout', 'attention_type'} was not found in config. Values will be initialized to default values.\n",
            "Downloading (…)cheduler_config.json: 100% 479/479 [00:00<00:00, 2.49MB/s]\n",
            "{'thresholding', 'dynamic_thresholding_ratio', 'clip_sample_range', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "> \u001b[1mINFO    Computing text embeddings for prompt: photo of sankii man\u001b[0m\n",
            "> \u001b[1mINFO    ***** Running training *****\u001b[0m\n",
            "> \u001b[1mINFO      Num examples = 15\u001b[0m\n",
            "> \u001b[1mINFO      Num batches each epoch = 15\u001b[0m\n",
            "> \u001b[1mINFO      Num Epochs = 250\u001b[0m\n",
            "> \u001b[1mINFO      Instantaneous batch size per device = 1\u001b[0m\n",
            "> \u001b[1mINFO      Total train batch size (w. parallel, distributed & accumulation) = 4\u001b[0m\n",
            "> \u001b[1mINFO      Gradient Accumulation steps = 4\u001b[0m\n",
            "> \u001b[1mINFO      Total optimization steps = 1000\u001b[0m\n",
            "> \u001b[1mINFO      Training config = {'model': 'stabilityai/stable-diffusion-xl-base-1.0', 'revision': None, 'tokenizer': None, 'image_path': 'images/', 'class_image_path': None, 'prompt': 'photo of sankii man', 'class_prompt': None, 'num_class_images': 100, 'class_labels_conditioning': None, 'prior_preservation': False, 'prior_loss_weight': 1.0, 'project_name': 'output/', 'seed': 42, 'resolution': 512, 'center_crop': False, 'train_text_encoder': False, 'batch_size': 1, 'sample_batch_size': 4, 'epochs': 250, 'num_steps': 1000, 'checkpointing_steps': 100000, 'resume_from_checkpoint': None, 'gradient_accumulation': 4, 'gradient_checkpointing': False, 'lr': 0.0001, 'scale_lr': False, 'scheduler': 'constant', 'warmup_steps': 0, 'num_cycles': 1, 'lr_power': 1.0, 'dataloader_num_workers': 0, 'use_8bit_adam': False, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 0.01, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'allow_tf32': False, 'prior_generation_precision': None, 'local_rank': -1, 'xformers': False, 'pre_compute_text_embeddings': False, 'tokenizer_max_length': None, 'text_encoder_use_attention_mask': False, 'rank': 4, 'xl': True, 'fp16': True, 'bf16': False, 'token': None, 'repo_id': None, 'push_to_hub': False, 'username': None, 'validation_prompt': None, 'num_validation_images': 4, 'validation_epochs': 50, 'checkpoints_total_limit': None, 'validation_images': None, 'logging': False}\u001b[0m\n",
            "Steps:   0% 0/1000 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/diffusers/models/attention_processor.py:1468: FutureWarning: `LoRAAttnProcessor2_0` is deprecated and will be removed in version 0.26.0. Make sure use AttnProcessor2_0 instead by settingLoRA layers to `self.{to_q,to_k,to_v,to_out[0]}.lora_layer` respectively. This will be done automatically when using `LoraLoaderMixin.load_lora_weights`\n",
            "  deprecate(\n",
            "Steps: 100% 1000/1000 [54:01<00:00,  3.00s/it, loss=0.3, lr=0.0001]    Model weights saved in output/pytorch_lora_weights.safetensors\n",
            "Steps: 100% 1000/1000 [54:02<00:00,  3.24s/it, loss=0.3, lr=0.0001]\n"
          ]
        }
      ],
      "source": [
        "!autotrain dreambooth \\\n",
        "--model stabilityai/stable-diffusion-xl-base-1.0 \\\n",
        "--project-name output/ \\\n",
        "--image-path images/ \\\n",
        "--prompt \"photo of sankii man\" \\\n",
        "--resolution 512 \\\n",
        "--batch-size 1 \\\n",
        "--num-steps 1000 \\\n",
        "--fp16 \\\n",
        "--gradient-accumulation 4 \\\n",
        "--lr 1e-4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VwRLpD9M0j3"
      },
      "outputs": [],
      "source": [
        "from diffusers import DiffusionPipeline, StableDiffusionXLImg2ImgPipeline\n",
        "import torch\n",
        "\n",
        "model = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "pipe = DiffusionPipeline.from_pretrained(\n",
        "    model,\n",
        "    torch_dtype=torch.float16,\n",
        ")\n",
        "pipe.to(\"cuda\")\n",
        "pipe.load_lora_weights(\"model/\", weight_name=\"pytorch_lora_weights.safetensors\")\n",
        "\n",
        "refiner = StableDiffusionXLImg2ImgPipeline.from_pretrained(\n",
        "    \"stabilityai/stable-diffusion-xl-refiner-1.0\",\n",
        "    torch_dtype=torch.float16,\n",
        ")\n",
        "refiner.to(\"cuda\")\n",
        "\n",
        "\n",
        "prompt = \"a portrait of sks dog, pixar, cartoon, 3d, headshots, fantasy, 4k, uhd\"\n",
        "\n",
        "for seed in range(10):\n",
        "    generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "    image = pipe(prompt=prompt, generator=generator, num_inference_steps=25)\n",
        "    image = image.images[0]\n",
        "    image.save(f\"images/{seed}.png\")\n",
        "    image = refiner(prompt=prompt, generator=generator, image=image)\n",
        "    image = image.images[0]\n",
        "    image.save(f\"images_refined/{seed}.png\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}